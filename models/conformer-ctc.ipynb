{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchaudio jiwer einops\n!apt-get install -y libsndfile1\n\n!mkdir -p ./data/librispeech ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T17:08:20.215687Z","iopub.execute_input":"2025-06-23T17:08:20.215962Z","iopub.status.idle":"2025-06-23T17:08:25.437697Z","shell.execute_reply.started":"2025-06-23T17:08:20.215944Z","shell.execute_reply":"2025-06-23T17:08:25.436860Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\nRequirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\nRequirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nlibsndfile1 is already the newest version (1.0.31-2ubuntu0.2).\n0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchaudio\nimport time\nimport numpy as np\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torchaudio.transforms import MelSpectrogram, Resample\nfrom einops import rearrange\nfrom tqdm import tqdm\nfrom jiwer import wer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T18:37:58.621538Z","iopub.execute_input":"2025-06-23T18:37:58.622284Z","iopub.status.idle":"2025-06-23T18:37:58.626895Z","shell.execute_reply.started":"2025-06-23T18:37:58.622259Z","shell.execute_reply":"2025-06-23T18:37:58.626054Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class LibriSpeechPreprocessor:\n    def __init__(self, sample_rate=16000, n_mels=80, n_fft=512, hop_length=256):\n        self.mel = MelSpectrogram(sample_rate=sample_rate, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n        self.resample = Resample(orig_freq=sample_rate, new_freq=sample_rate)\n\n    def __call__(self, waveform, sample_rate):\n        if sample_rate != 16000:\n            waveform = self.resample(waveform)\n        mel = self.mel(waveform)\n        mel = torch.log(torch.clamp(mel, min=1e-5))\n        mel = (mel - mel.mean()) / (mel.std() + 1e-5)\n        return mel.squeeze(0).T\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T18:38:08.234109Z","iopub.execute_input":"2025-06-23T18:38:08.234667Z","iopub.status.idle":"2025-06-23T18:38:08.239936Z","shell.execute_reply.started":"2025-06-23T18:38:08.234647Z","shell.execute_reply":"2025-06-23T18:38:08.239224Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class CharTokenizer:\n    def __init__(self):\n        self.vocab = \" abcdefghijklmnopqrstuvwxyz'\"\n        self.char2idx = {c: i for i, c in enumerate(self.vocab)}\n        self.idx2char = {i: c for i, c in enumerate(self.vocab)}\n        self.vocab_size = len(self.vocab)\n\n    def encode(self, text):\n        return [self.char2idx.get(c, 0) for c in text.lower()]\n\n    def decode(self, indices):\n        return ''.join([self.idx2char.get(i, '') for i in indices if i != 0])\n\ntokenizer = CharTokenizer()\n\nclass LibriSpeechDataset(torch.utils.data.Dataset):\n    def __init__(self, root, url, transform):\n        self.dataset = torchaudio.datasets.LIBRISPEECH(root, url=url, download=True)\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        waveform, sr, text, *_ = self.dataset[idx]\n        return self.transform(waveform, sr), text.lower()\n\n    def __len__(self):\n        return len(self.dataset)\n\ndef collate_fn(batch):\n    specs, texts = zip(*batch)\n    specs = [s for s in specs]\n    labels = [torch.tensor(tokenizer.encode(t)) for t in texts]\n    return (\n        pad_sequence(specs, batch_first=True),\n        torch.tensor([len(s) for s in specs]),\n        pad_sequence(labels, batch_first=True),\n        torch.tensor([len(l) for l in labels]),\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T18:38:14.958419Z","iopub.execute_input":"2025-06-23T18:38:14.959201Z","iopub.status.idle":"2025-06-23T18:38:14.970967Z","shell.execute_reply.started":"2025-06-23T18:38:14.959173Z","shell.execute_reply":"2025-06-23T18:38:14.970262Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\nclass ConformerBlock(nn.Module):\n    def __init__(self, d_model, heads, kernel_size):\n        super().__init__()\n        self.ff1 = nn.Sequential(\n            nn.LayerNorm(d_model),\n            nn.Linear(d_model, d_model * 4),\n            Swish(),\n            nn.Linear(d_model * 4, d_model)\n        )\n        self.self_attn = nn.MultiheadAttention(d_model, heads, batch_first=True)\n        self.ln1 = nn.LayerNorm(d_model)\n        self.conv = nn.Sequential(\n            nn.Conv1d(d_model, d_model * 2, 1),\n            nn.GLU(dim=1),\n            nn.Conv1d(d_model, d_model, kernel_size, padding=kernel_size // 2, groups=d_model),\n            nn.BatchNorm1d(d_model),\n            Swish(),\n            nn.Conv1d(d_model, d_model, 1)\n        )\n        self.ln2 = nn.LayerNorm(d_model)\n        self.ff2 = nn.Sequential(\n            nn.LayerNorm(d_model),\n            nn.Linear(d_model, d_model * 4),\n            Swish(),\n            nn.Linear(d_model * 4, d_model)\n        )\n\n    def forward(self, x):\n        x = x + 0.5 * self.ff1(x)\n        x = x + self.self_attn(x, x, x)[0]\n        x = self.ln1(x)\n        conv_input = rearrange(x, 'b t d -> b d t')\n        conv_out = self.conv(conv_input)\n        x = x + rearrange(conv_out, 'b d t -> b t d')\n        x = x + 0.5 * self.ff2(x)\n        return self.ln2(x)\n\nclass ConformerCTCModel(nn.Module):\n    def __init__(self, input_dim=80, d_model=256, num_blocks=8, heads=4, vocab_size=30):\n        super().__init__()\n        self.frontend = nn.Sequential(\n            nn.Conv1d(input_dim, d_model // 2, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv1d(d_model // 2, d_model, kernel_size=3, stride=2, padding=1),\n            nn.ReLU()\n        )\n        self.encoder = nn.Sequential(*[ConformerBlock(d_model, heads, kernel_size=15) for _ in range(num_blocks)])\n        self.fc = nn.Linear(d_model, vocab_size)\n\n    def forward(self, x):\n        x = x.permute(0, 2, 1)  # (B, F, T)\n        x = self.frontend(x)    # (B, D, T//4)\n        x = x.permute(0, 2, 1)  # (B, T//4, D)\n        x = self.encoder(x)\n        return self.fc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T18:38:34.758765Z","iopub.execute_input":"2025-06-23T18:38:34.759043Z","iopub.status.idle":"2025-06-23T18:38:34.768679Z","shell.execute_reply.started":"2025-06-23T18:38:34.759022Z","shell.execute_reply":"2025-06-23T18:38:34.767969Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def greedy_decode(preds):\n    return [\"\".join(tokenizer.decode([p for i, p in enumerate(seq) if p != 0 and (i == 0 or p != seq[i-1])])) for seq in preds]\n\ndef train_epoch(model, loader, optimizer, scheduler, criterion):\n    model.train()\n    total_loss, start = 0, time.time()\n    for x, xlen, y, ylen in tqdm(loader, desc=\"Train\"):\n        x, y = x.to(device), y.to(device)\n        out = model(x).permute(1, 0, 2)  # (T, B, C)\n        loss = criterion(out, y, xlen // 4, ylen)\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        optimizer.step()\n        scheduler.step()\n        total_loss += loss.item()\n    return total_loss / len(loader), time.time() - start\n\ndef evaluate(model, loader, criterion):\n    model.eval()\n    total_loss, total_wer = 0, 0\n    with torch.no_grad():\n        for x, xlen, y, ylen in tqdm(loader, desc=\"Eval\"):\n            x, y = x.to(device), y.to(device)\n            out = model(x).permute(1, 0, 2)\n            loss = criterion(out, y, xlen // 4, ylen)\n            total_loss += loss.item()\n            pred = torch.argmax(out, dim=-1).permute(1, 0)\n            hyp = greedy_decode(pred)\n            ref = [tokenizer.decode(t.cpu().numpy()) for t in y]\n            total_wer += wer(ref, hyp)\n    return total_loss / len(loader), total_wer / len(loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T18:38:42.885670Z","iopub.execute_input":"2025-06-23T18:38:42.885919Z","iopub.status.idle":"2025-06-23T18:38:42.893752Z","shell.execute_reply.started":"2025-06-23T18:38:42.885903Z","shell.execute_reply":"2025-06-23T18:38:42.893087Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"preprocessor = LibriSpeechPreprocessor()\ntrain_dataset = LibriSpeechDataset('./data/librispeech', 'train-clean-100', preprocessor)\ntrain_len = int(0.9 * len(train_dataset))\ntrain_data, val_data = random_split(train_dataset, [train_len, len(train_dataset) - train_len])\ntest_data = LibriSpeechDataset('./data/librispeech', 'test-clean', preprocessor)\n\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_data, batch_size=8, collate_fn=collate_fn)\ntest_loader = DataLoader(test_data, batch_size=8, collate_fn=collate_fn)\n\nmodel = ConformerCTCModel(vocab_size=tokenizer.vocab_size).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4, steps_per_epoch=len(train_loader), epochs=10)\ncriterion = nn.CTCLoss(blank=0, zero_infinity=True)\n\nfor epoch in range(1, 11):\n    print(f\"\\nEpoch {epoch}\")\n    train_loss, train_time = train_epoch(model, train_loader, optimizer, scheduler, criterion)\n    val_loss, val_wer = evaluate(model, val_loader, criterion)\n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val WER: {val_wer:.2%} | Time: {train_time:.2f}s\")\n    torch.save(model.state_dict(), f\"conformer_ctc_epoch{epoch}.pth\")\n\ntest_loss, test_wer = evaluate(model, test_loader, criterion)\nprint(f\"\\nTest Loss: {test_loss:.4f} | Test WER: {test_wer:.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T18:38:49.378962Z","iopub.execute_input":"2025-06-23T18:38:49.379526Z","iopub.status.idle":"2025-06-23T19:54:03.711543Z","shell.execute_reply.started":"2025-06-23T18:38:49.379502Z","shell.execute_reply":"2025-06-23T19:54:03.710816Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:29<00:00,  8.24it/s]\nEval: 100%|██████████| 357/357 [00:52<00:00,  6.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5304 | Val Loss: 1.6734 | Val WER: 100.00% | Time: 389.56s\n\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:28<00:00,  8.27it/s]\nEval: 100%|██████████| 357/357 [00:52<00:00,  6.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5694 | Val Loss: 1.5625 | Val WER: 100.00% | Time: 388.34s\n\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:29<00:00,  8.25it/s]\nEval: 100%|██████████| 357/357 [00:57<00:00,  6.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4488 | Val Loss: 1.4636 | Val WER: 100.00% | Time: 389.23s\n\nEpoch 4\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:28<00:00,  8.26it/s]\nEval: 100%|██████████| 357/357 [01:00<00:00,  5.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2988 | Val Loss: 1.3218 | Val WER: 100.00% | Time: 388.88s\n\nEpoch 5\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:27<00:00,  8.30it/s]\nEval: 100%|██████████| 357/357 [00:57<00:00,  6.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1646 | Val Loss: 1.1460 | Val WER: 100.00% | Time: 387.01s\n\nEpoch 6\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:27<00:00,  8.29it/s]\nEval: 100%|██████████| 357/357 [00:59<00:00,  5.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0554 | Val Loss: 1.0904 | Val WER: 100.00% | Time: 387.34s\n\nEpoch 7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:27<00:00,  8.28it/s]\nEval: 100%|██████████| 357/357 [01:00<00:00,  5.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9522 | Val Loss: 0.9866 | Val WER: 100.00% | Time: 387.90s\n\nEpoch 8\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:28<00:00,  8.26it/s]\nEval: 100%|██████████| 357/357 [01:01<00:00,  5.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8564 | Val Loss: 0.9451 | Val WER: 100.00% | Time: 388.75s\n\nEpoch 9\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:27<00:00,  8.28it/s]\nEval: 100%|██████████| 357/357 [01:01<00:00,  5.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7776 | Val Loss: 0.9115 | Val WER: 100.00% | Time: 387.92s\n\nEpoch 10\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 3211/3211 [06:27<00:00,  8.30it/s]\nEval: 100%|██████████| 357/357 [01:01<00:00,  5.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7321 | Val Loss: 0.9134 | Val WER: 100.00% | Time: 387.00s\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 328/328 [00:44<00:00,  7.39it/s]","output_type":"stream"},{"name":"stdout","text":"\nTest Loss: 0.7932 | Test WER: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}